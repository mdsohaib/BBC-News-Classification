{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing important libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('bbc-text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      "category    2225 non-null object\n",
      "text        2225 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['category', 'text'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\md sohaib\n",
      "[nltk_data]     uddin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#cleaning the texts\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus=[]\n",
    "for i in range(0, 2225):\n",
    "    text = re.sub('[^a-zA-Z]',' ', df['text'][i])\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    ps= PorterStemmer()\n",
    "    text=[ps.stem(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#cleaning the texts\\n# token normalization using Lemmatization\\nimport re\\nimport nltk\\nnltk.download('stopwords')\\nnltk.download('wordnet')\\nfrom nltk.corpus import stopwords\\nfrom nltk.stem import WordNetLemmatizer\\ncorpus=[]\\nfor i in range(0, 2225):\\n    text = re.sub('[^a-zA-Z]',' ', df['text'][i])\\n    text = text.lower()\\n    text = text.split()\\n    ps= WordNetLemmatizer()\\n    text=[ps.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\\n    text=' '.join(text)\\n    corpus.append(text)\\n    \""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#cleaning the texts\n",
    "# token normalization using Lemmatization\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "corpus=[]\n",
    "for i in range(0, 2225):\n",
    "    text = re.sub('[^a-zA-Z]',' ', df['text'][i])\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    ps= WordNetLemmatizer()\n",
    "    text=[ps.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
    "    text=' '.join(text)\n",
    "    corpus.append(text)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom boss left book alon former worldcom boss berni ebber accus overse bn bn fraud never made account decis wit told juror david myer made comment question defenc lawyer argu mr ebber respons worldcom problem phone compani collaps prosecutor claim loss hidden protect firm share mr myer alreadi plead guilti fraud assist prosecutor monday defenc lawyer reid weingarten tri distanc client alleg cross examin ask mr myer ever knew mr ebber make account decis awar mr myer repli ever know mr ebber make account entri worldcom book mr weingarten press repli wit mr myer admit order fals account entri request former worldcom chief financi offic scott sullivan defenc lawyer tri paint mr sullivan admit fraud testifi later trial mastermind behind worldcom account hous card mr ebber team meanwhil look portray affabl boss admiss pe graduat economist whatev abil mr ebber transform worldcom rel unknown bn telecom giant investor darl late worldcom problem mount howev competit increas telecom boom peter firm final collaps sharehold lost bn worker lost job mr ebber trial expect last two month found guilti former ceo face substanti jail sentenc firmli declar innoc'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the bag of words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv= CountVectorizer(max_features = 3000)\n",
    "X= cv.fit_transform(corpus).toarray()\n",
    "y= df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB accuracy: 91.69%\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(\"NB accuracy: {:.2f}%\".format(nb.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN accuracy: 75.96%\n"
     ]
    }
   ],
   "source": [
    "#KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn =  KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"KNN accuracy: {:.2f}%\".format(knn.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 96.18%\n"
     ]
    }
   ],
   "source": [
    "# Random forset\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state= 1)\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Random Forest accuracy: {:.2f}%\".format(rf.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XG boost accuracy: 95.51%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#XG boost\n",
    "import xgboost\n",
    "classifier=xgboost.XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"XG boost accuracy: {:.2f}%\".format(classifier.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
